{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bayesian Modelling with Lumen\n",
    "\n",
    "This notebook showcases how the Lumen project can be utilized for Bayesian modelling.\n",
    "\n",
    "Bayesian modelling can be done with Probabilistic Programming Languages, such as PyMC3 or Stan.\n",
    "Lumen neatly integrated with PyMC3 (and Stan, which is under development), that is it you export your\n",
    "PyMC3 model to Lumen with a single call. Once exported, you can visually explore, debug, and validate your model.\n",
    " No further coding required!\n",
    "\n",
    "## Bayesian Modeling Overview\n",
    "\n",
    "Bayesian Modelling can be separated into the following stages.\n",
    "\n",
    "  0. data collection:\n",
    "  1. data exploration: understand existing structure in your data, find issues with data quality, develop hypothesis\n",
    "  how to structure your model to solve your problem\n",
    "  2. model setup: describe model in term of a PPL\n",
    "  3. model validation: check if the model does what you want and expect it to do.\n",
    "  4. model deployment:\n",
    "\n",
    "Typically this is an very incremental workflow where at first you start with a simple model which\n",
    "thereafter is improved by changing the model, it's underlying distributions, by incooperating more data,\n",
    "by differently perprocessing the data, ...\n",
    "\n",
    "Often times there actually is not observable data available, hence the steps involving data exploratino and validation\n",
    "with respect to traning or test data become obsolete. However, there is still the need to validate, debug and improve\n",
    "the model - tasks with which Lumen may support you.\n",
    "\n",
    "## How does Lumen help with Bayesian Modeling\n",
    "\n",
    "Lumen allows you to:\n",
    "\n",
    "   * export a PyMC3 model to Lumen in a single call\n",
    "   * visually and interactively explore models:\n",
    "      * understand prior and posterior distribution (that is, of the paramters/latent variables)\n",
    "      * understand prior predictive and posterior predictive distribution (that is of the observable variables)\n",
    "      * compare multiple increments of a model side by side\n",
    "      * compare model distribution with data distribution (training or test data)\n",
    "      * use Posterior Predictive Checks for validation\n",
    "\n",
    "\n",
    "## Overview on Lumen\n",
    "\n",
    "Lumen consists of a backend and a front end part.\n",
    "\n",
    "### Backend\n",
    "The backend serves two purposes:\n",
    " 1. manage models, watch a specific directory for new models/changed models, and\n",
    " 2. provide an API to run complex inference queries on models.\n",
    "\n",
    "You may use the API directly (see also: TODO) to run inference queries, however, in many\n",
    "cases it maybe much more convenient to use the front-end instead.\n",
    "If you wonder what queries are, then you may imagine them as specific questions, that you ask the model.\n",
    "Here are some examples:\n",
    "\n",
    "  * 'How does that marginal distribution of the variable \"age\" look like?'\n",
    "  * 'What is the most likely value for \"income\" given that a person has \"low education\"?'\n",
    "  * 'What do samples drawn from the model look like for the variables \"east-west\" and \"age\"?\n",
    "\n",
    "### Frontend\n",
    "The front-end gives you a visual interactive interface to configure, run and visualize a wide\n",
    "range of possibly complex queries.\n",
    "It does not require any programming from your side. The front-end connects\n",
    "to an instance of the backend to actually execute any queries."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example Modelling Workflow\n",
    "\n",
    "The following shows a simple step-by-step example how a model is iteratively refined, and how each iterate\n",
    "analyzed with the Lumen frontend to validate and debug it.\n",
    "\n",
    "A precondition is that you have both frontend and backend installed on your machine.\n",
    "\n",
    "_last time tested: 2020-09-22_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import mb_modelbase as mb\n",
    "\n",
    "# folder in which we will store models\n",
    "models_path = './models_bayesian_modeling_example'\n",
    "import os\n",
    "if not os.path.exists(models_path):\n",
    "    os.makedirs(models_path)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Start Lumen\n",
    "\n",
    "To work with Lumen we simply have to:\n",
    " 1. start the back-end,\n",
    " 2. start the front-end, and\n",
    " 3. export each PyMC3 model increment and save it in the folder `models_path` so that we can use it with Lumen.\n",
    "\n",
    "#### Back-End\n",
    "The backend watches for changes in a folder.\n",
    "Run the following on a separate console to start the backend and let it watch models in the specified folder:\n",
    "\n",
    "```\n",
    "cd <dir-where-you-cloned-the-backend-source-to>\n",
    "python3 bin/webservice.py --d jupyter/models_bayesian_modeling_example\n",
    "```\n",
    "\n",
    "#### Front-End\n",
    "The front-end is by default configured to use a local backend, that is, you don't have to do anything, but run it.\n",
    "Simply open its `index.html` with a browser (preferably, chrome/chromium based).\n",
    "\n",
    "Now, backend and frontend are ready. Let's start with the modelling workflow and create some models... !"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collect data\n",
    "\n",
    "Here, we simply create some fake observed data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "alpha, sigma = 1, 1\n",
    "beta_0 = 1\n",
    "beta_1 = 2.5\n",
    "size = 100\n",
    "X1 = np.random.randn(size)\n",
    "X2 = np.random.randn(size) * 0.2\n",
    "Y = alpha + beta_0 * X1 + beta_1 * X2 + np.random.randn(size) * sigma\n",
    "data = pd.DataFrame({'X1': X1, 'X2': X2, 'Y': Y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exploration of observed data\n",
    "\n",
    "Let's use Lumen to explore our observed data. To do so, we have to wrap it in a model and save it our models directory.\n",
    "Here, we use a simple histogram estimator. You may also use a Kernel-Density-Estimator by changing the parameter\n",
    "`model_type` to 'kde'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_empirical = mb.make_empirical_model(modelname='data_empirical', output_directory=models_path, df=data, model_type='empirical')\n",
    "#model_kde = mb.make_empirical_model(modelname='data_kde', output_directory=models_path, df=data, model_type='kde')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After execution of the previous cell, have a look at Lumen. It should inform you that a new model was found:\n",
    "\n",
    "![Screenhot](img/new_model_found.png)\n",
    "\n",
    "You can now explore it! Have fun ;)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creation of initial PyMC3 model\n",
    "\n",
    "Let's now create a very basic first model using PyMC3. This illustrates how the wrapping/the export to Lumen is done."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "15:06:40.282 INFO :: Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "15:06:40.284 INFO :: Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "15:06:42.631 INFO :: Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [sigma, beta_1, beta_0, alpha]\n",
      "15:06:42.633 INFO :: NUTS: [sigma, beta_1, beta_0, alpha]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "15:06:47.260 INFO :: Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "100%|██████████| 5000/5000 [00:13<00:00, 384.29it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-1770511104e4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;31m## Save model the folder to that it shows up in front-end\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m \u001B[0mmodel_1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodels_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Model' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "model_name = \"model_1\"\n",
    "model_1 = pm.Model()\n",
    "\n",
    "with model_1:\n",
    "    # Priors for unknown model parameters\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=10)\n",
    "    beta_0 = pm.Normal('beta_0', mu=0, sd=10)\n",
    "    beta_1 = pm.Normal('beta_1', mu=0, sd=20)\n",
    "    sigma = pm.HalfNormal('sigma', sd=5)\n",
    "    \n",
    "    # Expected value of outcome\n",
    "    mu = alpha + beta_0 * data['X1'] + beta_1 * data['X2']\n",
    "    \n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y = pm.Normal('Y', mu=mu, sd=sigma, observed=data['Y'])\n",
    "    X1 = pm.Normal('X1', mu=data['X1'], sd=sigma, observed=data['X1'])\n",
    "    X2 = pm.Normal('X2', mu=data['X2'], sd=sigma, observed=data['X2'])\n",
    "\n",
    "    ## wrap PyMC3 model with Lumen!\n",
    "    model = mb.ProbabilisticPymc3Model(model_name, model_1)\n",
    "    model.fit(data)\n",
    "\n",
    "## Save model the folder to that it shows up in front-end\n",
    "model_1.save(models_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The initial model pops up in the front-end and is available for exploration:\n",
    "\n",
    "![Screenhot](img/new_model_found_2.png)\n",
    "\n",
    "We easily see, for instance, that the resulting posterior predictive distributions of X1 and X2 do not fit well\n",
    "with the observed empirical distributions:\n",
    "\n",
    "![Screenhot](img/model1_misfit.png)\n",
    "\n",
    "We could now improve the model and check the new increment ... :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pymc3' has no attribute 'unIF'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-c6b1bc7d4e7c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0malpha\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUniform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'alpha'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mbeta_0\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNormal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'beta_0'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0mbeta_1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munIF\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'beta_1'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m     \u001B[0msigma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mHalfNormal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'sigma'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'pymc3' has no attribute 'unIF'"
     ]
    }
   ],
   "source": [
    "# TODO: make a new model\n",
    "# create modified PPL model with PyMC3\n",
    "model_2 = pm.Model()\n",
    "model_name = \"model_2\"\n",
    "\n",
    "with model_2:\n",
    "    # Priors for unknown model parameters\n",
    "    alpha = pm.Uniform('alpha')\n",
    "    beta_0 = pm.Normal('beta_0', mu=20, sd=1)\n",
    "    beta_1 = pm.unIF('beta_1', mu=5, sd=1)\n",
    "    sigma = pm.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    # Expected value of outcome\n",
    "    mu = alpha + beta_0 * data['X1'] + beta_1 * data['X2']\n",
    "    \n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y = pm.Normal('Y', mu=mu, sd=sigma, observed=data['Y'])\n",
    "    X1 = pm.Normal('X1', mu=data['X1'], sd=sigma, observed=data['X1'])\n",
    "    X2 = pm.Normal('X2', mu=data['X2'], sd=sigma, observed=data['X2'])\n",
    "    \n",
    "    model = mb.ProbabilisticPymc3Model(model_name, model_2)\n",
    "    model.fit(data)\n",
    "    \n",
    "# we could reuse the empirical model of model_1. However, this only works if the data didn't change.\n",
    "#model_2.set_empirical_model_name(model_1.get_empiricial_model_name())\n",
    "\n",
    "model_2.save(models_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}